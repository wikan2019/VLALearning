# 20. 动作表示：从离散 Token 到扩散生成

## 1. 为什么"动作表示"是 VLA 的核心问题？

VLM 的输出是文本 Token（离散的、有限词表的）。但机器人动作是**连续的、高维的、高精度的**：

```
文本 Token：   "hello" → [15339]           （离散，有限词表，精度无所谓）
机器人动作：   Δx = 0.0237m                （连续，无限精度，毫米级误差就会导致抓取失败）
```

**核心矛盾**：如何用一个基于离散 Token 的语言模型来输出高精度的连续动作？

这就是"动作表示 (Action Representation / Action Tokenization)"问题——VLA 区别于 VLM 的最本质差异。

## 2. 为什么 VLA 没有直接用 Regression Head？

在深入各种动作表示方法之前，先回答一个最直觉的问题：既然机器人动作是连续值，**为什么不直接在 LLM 后面接一个 MLP Regression Head，用 MSE Loss 回归出动作？**

### (a) Regression Head 的做法

```
Regression Head (最朴素的方案):
  [Image] [Text] → VLM → Hidden State h ∈ R^d
                                         ↓
                         MLP: h → â = W₂·ReLU(W₁·h + b₁) + b₂ ∈ R^7
                                         ↓
                         训练: L = ||â - a*||²  (MSE Loss)
```

这看起来是最直接、最高效的方案——**一次前向传播就得到连续动作**，没有离散化损失，没有去噪迭代。

### (b) 致命问题 1：多模态分布下的 Mode Averaging

**MSE Loss 隐含了一个关键假设：目标是单峰高斯分布。**

数学推导：MSE 最小化的最优解是条件期望

```
MSE 最优解推导：

  L(θ) = E_{(o,a)~D} [ ||f_θ(o) - a||² ]

  对 f_θ(o) 求导令其为 0：

  ∂L/∂f_θ(o) = E_{a|o} [ 2(f_θ(o) - a) ] = 0

  → f_θ*(o) = E_{a|o}[a] = ∫ a · p(a|o) da

  即：MSE 的最优解是 p(a|o) 的条件均值！
```

**当动作分布是多峰的时，条件均值恰好落在两个峰之间的"无人区"：**

```
场景: "把杯子放到桌上" → 左边放 ✅ 右边放 ✅

真实的 p(a|o):           Regression Head 的输出:
                          
概率 ↑   ╱╲    ╱╲       概率 ↑      ↓ f*(o) = E[a|o]
    │   ╱  ╲  ╱  ╲          │      │
    │  ╱    ╲╱    ╲          │      ●  ← 条件均值
    │ ╱            ╲         │      │     (两峰中间！)
    └──────────────→ a       └──────────→ a
     左    中间    右        这个"中间"动作往往是无效的

MSE 产生的动作 = (左 + 右) / 2 = 中间 = 放不下去 ❌
```

**具体例子：**

```
数值示例:
  p(Δx | o) = 0.5·N(-0.1, 0.01²) + 0.5·N(+0.1, 0.01²)
              ↑ 放在左边              ↑ 放在右边

  Regression Head 输出:
    f*(o) = 0.5×(-0.1) + 0.5×(+0.1) = 0.0  ← 悬在空中！

  扩散模型/Flow Matching 输出:
    采样 1: Δx = -0.098 (从左峰采样) ✅
    采样 2: Δx = +0.102 (从右峰采样) ✅
```

### (c) 致命问题 2：表达能力受限

Regression Head 本质上只能表示**一个确定性的点估计**：

```
输入 o → 模型 → 输出 â (一个确定的向量)

这意味着：
  同一个观测 o，模型永远只能给出同一个动作 â
  → 完全无法表达 "这个场景有多种正确做法" 的不确定性
```

| 表示方式 | 能否表达多模态？ | 能否表达不确定性？ | 原因 |
| :--- | :--- | :--- | :--- |
| **Regression Head** | ❌ | ❌ | 输出确定性点估计 |
| **分类头 (Binning)** | ⚠️ 有限 | ✅ 输出概率分布 | 离散近似限制了表达 |
| **扩散/Flow Matching** | ✅ | ✅ 采样产生多样性 | 学习完整的条件分布 |

### (d) 致命问题 3：梯度信号不均匀

MSE Loss 对大误差和小误差的梯度量级差异巨大：

```
MSE 梯度: ∂L/∂â = 2(â - a*)

问题：
  大误差时 (â 离 a* 远): 梯度很大 → 训练被粗糙动作主导
  小误差时 (â 接近 a*):  梯度很小 → 精细调整能力不足

结果：模型"勉强及格"但难以"精益求精"
      → 对于灵巧操作（插钉入孔: 需要 <0.5mm 精度），这是致命的
```

### (e) 扩散/Flow Matching 能否避免梯度不均匀？

答案是：**能，而且这是扩散/Flow Matching 相比 Regression Head 的一个关键但常被忽视的优势。**

#### 根本原因：训练目标不同

Regression Head 直接预测动作本身，而扩散/Flow Matching 预测的是**噪声**或**速度**——这两个目标的数值量级是固定的，与"距离正确动作有多远"无关。

```
Regression Head:
  预测目标 = 动作本身 a*
  损失: L = ||â - a*||²
  梯度: ∂L/∂â = 2(â - a*)     ← 梯度大小 ∝ 误差大小 (不均匀!)

DDPM (扩散):
  预测目标 = 加入的噪声 ε ~ N(0, I)
  损失: L = ||ε_θ(a_t, t) - ε||²
  梯度: ∂L/∂θ ∝ (ε_θ - ε)    ← 目标 ε 始终是标准正态，量级恒定 ≈ O(1)

Flow Matching:
  预测目标 = 速度 v = a₁ - a₀,  其中 a₀ ~ N(0,I)
  损失: L = ||v_θ(a_t, t) - v||²
  梯度: ∂L/∂θ ∝ (v_θ - v)     ← 目标 v 的量级也是 O(1)
```

**关键区别**：不管模型当前预测得好不好、不管距离最终动作有多远，噪声 ε 和速度 v 的目标值始终保持在相同的数值范围内。这意味着梯度信号始终是有意义的、量级均匀的。

#### 数值对比

```
场景: 真实动作 a* = 0.050m, 模型当前预测 â

═══════════════════════════════════════════════════════════════
情况 1: 模型预测差 (â = 0.200m, 误差 = 0.150m)
═══════════════════════════════════════════════════════════════

  Regression Head:
    梯度 = 2 × (0.200 - 0.050) = 0.300          ← 大梯度

  DDPM (某个时间步 t):
    目标噪声 ε = 1.23 (标准正态采样)
    预测噪声 ε_θ = 0.87
    梯度 ∝ (0.87 - 1.23) = -0.36                 ← O(1) 量级

═══════════════════════════════════════════════════════════════
情况 2: 模型预测好 (â = 0.051m, 误差 = 0.001m)
═══════════════════════════════════════════════════════════════

  Regression Head:
    梯度 = 2 × (0.051 - 0.050) = 0.002           ← 极小梯度!
    → 模型几乎收不到"继续优化"的信号

  DDPM (某个时间步 t):
    目标噪声 ε = -0.72
    预测噪声 ε_θ = -0.45
    梯度 ∝ (-0.45 - (-0.72)) = 0.27              ← 仍然是 O(1) 量级!
    → 模型持续收到有效的训练信号

梯度比值:
  Regression: 情况1/情况2 = 0.300/0.002 = 150 倍差异!
  DDPM:       情况1/情况2 = 0.36/0.27   = 1.3 倍差异
```

#### 多尺度去噪：天然的精度课程学习

扩散/Flow Matching 还有一个更深层的优势——**不同噪声水平 t 天然对应不同精度的学习**：

```
时间步 t 的作用 (以 Flow Matching 为例):

  t ≈ 0 (接近纯噪声):
    a_t ≈ 噪声，距离真实动作很远
    → 模型需要学习: "大致往哪个方向走？"
    → 对应: 粗粒度结构 (是向左还是向右？)

  t ≈ 0.5 (中间状态):
    a_t = 噪声和数据的混合
    → 模型需要学习: "方向对了，具体走多远？"
    → 对应: 中粒度调整 (到达大致位置)

  t ≈ 1 (接近真实数据):
    a_t ≈ 真实动作 + 微量噪声
    → 模型需要学习: "微调到精确位置"
    → 对应: 细粒度精调 (亚毫米精度)
    → 此时梯度信号依然充分！因为预测的是噪声/速度，不是动作残差

训练时 t 均匀采样 → 粗/中/细三个层次获得均等的训练机会:

  ┌──────┬──────────────────────────────────────────────┐
  │ t≈0  │ ████████████  学粗粒度结构 (方向)             │
  ├──────┼──────────────────────────────────────────────┤
  │ t≈0.5│ ████████████  学中粒度结构 (位置)             │
  ├──────┼──────────────────────────────────────────────┤
  │ t≈1  │ ████████████  学细粒度结构 (精度)  ← 同等权重 │
  └──────┴──────────────────────────────────────────────┘

  对比 Regression Head:
  ┌──────────┬─────────────────────────────────────────┐
  │ 大误差   │ ██████████████████  主导训练              │
  ├──────────┼─────────────────────────────────────────┤
  │ 中误差   │ ████████  适中                            │
  ├──────────┼─────────────────────────────────────────┤
  │ 小误差   │ █  几乎学不到   ← 精细操作能力不足       │
  └──────────┴─────────────────────────────────────────┘
```

#### 推理时的迭代精化

推理时，扩散/Flow Matching 的多步去噪过程本身就是一个**从粗到细的精化过程**：

```
Flow Matching 推理 (10 步):

  Step 0:  a₀ = [0.8, -0.3, ...]       ← 纯噪声
  Step 1:  a₁ = [0.4, -0.1, ...]       ← 粗方向正确
  Step 2:  a₂ = [0.15, 0.02, ...]      ← 大致位置对了
  ...
  Step 8:  a₈ = [0.0508, 0.0197, ...]  ← 接近目标
  Step 9:  a₉ = [0.0502, 0.0201, ...]  ← 精确微调
  Step 10: a₁₀ = [0.0500, 0.0200, ...] ← 最终精度 ~0.02mm ✅

  每一步都基于上一步的结果做局部优化
  → 最后几步专门用于精细调整
  → Regression Head 没有这种"精化机会"，一次前向就定死了
```

#### 总结对比

| | Regression Head (MSE) | 扩散/Flow Matching |
| :--- | :--- | :--- |
| **训练目标** | 预测动作本身 | 预测噪声/速度（量级恒定） |
| **梯度量级** | ∝ 误差大小（不均匀） | ≈ O(1)（均匀） |
| **精细调整信号** | 接近收敛时梯度消失 | 始终有充分梯度 |
| **精度课程** | 无（大误差主导） | 有（不同 t 对应不同精度层次） |
| **推理精化** | 单次前向，不可修正 | 多步迭代，逐步精化 |
| **实测精细操作** | 精度不足 | **亚毫米级精度** |

> **关键结论**：扩散/Flow Matching 通过将"预测动作"转化为"预测噪声/速度"，从根本上消除了梯度信号与误差大小挂钩的问题。加上多尺度训练和迭代精化的推理方式，使其在精细操作上远优于 Regression Head。这也是 π0 等前沿 VLA 选择 Flow Matching 的重要原因之一。

---

### (f) 为什么分类头也不完美？

分类头（Binning）虽然能通过 softmax 输出概率分布，但：

```
分类头: Δx ∈ [-0.1, 0.1] → 256 个 Bin → softmax → 概率分布

优势: 可以表示多模态！softmax 可以在多个 Bin 上给出高概率
问题: 256 个 Bin 的精度 ≈ 0.8mm，对精细操作仍然不够
      且各维度独立分类，无法建模维度间的联合分布
```

### (g) 最优解：扩散/Flow Matching

扩散模型和 Flow Matching 是目前的最优解，因为它们：

```
✅ 学习完整的条件分布 p(a|o)，而非点估计 E[a|o]
✅ 输出连续值，无离散化精度损失
✅ 通过随机采样天然支持多模态分布
✅ 一次生成所有维度，建模联合分布
```

**各方案完整对比：**

| | Regression Head | 分类头 (Binning) | 扩散 (DDPM) | **Flow Matching** |
| :--- | :--- | :--- | :--- | :--- |
| **输出类型** | 点估计 | 离散概率分布 | 连续采样 | 连续采样 |
| **多模态分布** | ❌ Mode Average | ⚠️ 粗糙近似 | ✅ | ✅ |
| **精度** | 高（连续值） | 中（256 Bin） | 最高 | 最高 |
| **推理速度** | ⭐⭐⭐⭐⭐ | ⭐⭐⭐ | ⭐（多步去噪） | ⭐⭐⭐（少步ODE） |
| **训练复杂度** | 最低 | 低 | 高 | 中 |
| **代表** | 简单 BC | RT-2, OpenVLA | Diffusion Policy | **π0** |

> **关键结论**：Regression Head 速度最快但无法处理多模态分布，这在机器人操作中几乎无处不在（多条合理轨迹、不同抓取角度、多个放置位置）。Flow Matching 在保持连续精度的同时，用比 DDPM 更少的推理步数实现了多模态建模，成为当前 VLA 的最佳动作生成方案。

> **详细了解 Flow Matching 原理**：请参考附录 [Appendix A: Flow Matching 原理详解](./Appendix_A_Flow_Matching.md)

---

## 3. 四大动作表示方法

### (a) 方法一：均匀离散化 (Uniform Binning)

**代表**：RT-2, OpenVLA

**原理**：将每个动作维度均匀切分为 N 个区间 (Bin)，把回归问题转化为分类问题。

```
动作空间 Δx ∈ [-0.1, 0.1]
切分为 256 个 Bin：
  Bin 0 = [-0.100, -0.099]
  Bin 1 = [-0.099, -0.098]
  ...
  Bin 128 = [0.000, 0.001]  ← 零点附近
  ...
  Bin 255 = [0.099, 0.100]

实际动作 Δx = 0.0237 → 映射到 Bin 153 → 解码为 ≈ 0.024
```

**7 维动作 → 7 个分类 Token**，直接用 LLM 的词表生成。

| 优点 | 缺点 |
| :--- | :--- |
| 实现极简，直接复用 LLM 框架 | 精度有限（256 Bin → 分辨率 ~0.8mm） |
| 不需要额外的动作解码头 | 各维度独立预测，忽略维度间关联 |
| 训练稳定 | 对高频控制任务（灵巧操作）精度不够 |

### (b) 方法二：FAST（频域动作序列编码）

**代表**：π0-FAST（Physical Intelligence, 2025.01）

**动机**：均匀 Binning 的两个根本问题：
1.  **精度不够**：灵巧操作（如拧螺丝）需要亚毫米精度。
2.  **效率太低**：每步 7 个 Token × 16 步 Action Chunk = 112 个 Token 要逐个生成。

**核心思想**：用**离散余弦变换 (DCT)** 将动作序列从时域压缩到频域。

```
时域动作序列 (16 步 × 7 维 = 112 个值)：
  [0.02, 0.03, 0.04, 0.05, ...]  ← 原始动作序列，变化平滑
       ↓ DCT 变换
频域系数 (保留前 K 个低频分量)：
  [0.15, -0.03, 0.01, ...]        ← 大幅压缩！只需 ~20 个系数
       ↓ 量化为 Token
  [Token_1, Token_2, ..., Token_20]
```

**为什么有效？** 机器人动作在时间上通常是**平滑的**（不会突然从左跳到右），所以大部分能量集中在低频分量上。DCT 可以用少量系数高精度重建整段动作。

| 优点 | 缺点 |
| :--- | :--- |
| **压缩率高**：112 个值 → ~20 个 Token | 需要训练专用的 Tokenizer |
| **精度高**：保留了动作的连续特性 | 对突变动作（碰撞）重建有损 |
| **速度快**：Token 数大幅减少 → 自回归更快 | DCT 假设动作平滑，极端情况失效 |
| **通用性强**：FAST+ 在 100 万轨迹上预训练 | — |

**关键成果**：π0-FAST 在保持与扩散版 π0 相同性能的同时，训练时间减少 **5 倍**。

### (c) 方法三：扩散策略 (Diffusion Policy)

**代表**：π0, Octo, Diffusion Policy (Chi et al. 2023)

**核心思想**：不用离散 Token，而是用**扩散模型 (Diffusion Model)** 直接生成连续动作。

```
噪声动作 a_T ~ N(0, I)    （纯噪声）
      ↓  去噪步骤 1 (条件：图像 + 语言 + 本体)
半噪声动作 a_{T-1}
      ↓  去噪步骤 2
      ...
      ↓  去噪步骤 T
干净动作 a_0 = [0.0237, -0.0103, 0.0491, ...]   （高精度连续值）
```

**关键优势：建模多模态分布**

同一个任务可能有多种正确做法（从左边绕或从右边绕），自回归只能输出一种，扩散可以建模完整的分布：

```
         ┌─ 方案 A: 从左边绕过障碍物
任务 ──→ │
         └─ 方案 B: 从右边绕过障碍物

自回归输出：取平均 → 直直撞上障碍物（灾难！）
扩散输出：  随机采样一种方案 → 完整地从一侧绕过 ✅
```

| 优点 | 缺点 |
| :--- | :--- |
| **精度最高**：输出连续值，无量化误差 | 去噪需要多步迭代 (~10步) |
| **多模态分布**：避免 mode averaging 灾难 | 推理速度慢 |
| **Action Chunking 自然**：一次生成整段轨迹 | 训练比自回归复杂 |
| 适合灵巧操作（精细拧装、布料折叠） | 与 LLM 自回归框架不统一 |

### (d) 方法四：离散扩散 (Discrete Diffusion VLA)

**代表**：Discrete Diffusion VLA（2025）

**动机**：扩散策略精度高但与 LLM 框架不统一；自回归统一但精度低。能否两全？

**核心思想**：在 LLM 的 Transformer 骨干内部，用**离散扩散**代替自回归来生成动作 Token。

```
输入:  [Image] [Text] [Mask Mask Mask Mask Mask Mask Mask]  ← 7 个被遮蔽的动作位置
                          ↓ 离散扩散去噪
步骤1: [Image] [Text] [?    ?    128  ?    ?    ?    ?]      ← 先解码最"容易"的维度
步骤2: [Image] [Text] [?    91   128  241  ?    ?    ?]
步骤3: [Image] [Text] [1    91   128  241  5    101  128]    ← 全部解码完成
```

**关键创新**：
*   **自适应解码顺序**：先解码确信度高的维度，再解码难的（不像自回归固定从左到右）。
*   **纠错机制 (Re-masking)**：解码后可以重新遮蔽不确信的 Token 再解码一次。

| 优点 | 缺点 |
| :--- | :--- |
| 与 LLM Transformer **统一架构** | 仍然是离散 Token，精度受限于 Bin 数 |
| 维度间建模**联合分布** | 较新，还在验证阶段 |
| 并行解码（不需要逐个生成） | — |

## 4. 四种方法总对比

| 方法 | 精度 | 速度 | 多模态分布 | 与 LLM 统一 | 代表 |
| :--- | :--- | :--- | :--- | :--- | :--- |
| **均匀 Binning** | 中 | ⭐⭐⭐ | ❌ | ✅ 完全统一 | RT-2, OpenVLA |
| **FAST (频域)** | 高 | ⭐⭐⭐⭐ | ❌ | ✅ Token 生成 | π0-FAST |
| **扩散策略** | ⭐⭐⭐⭐⭐ | ⭐ | ✅ | ❌ 需额外头 | π0, Octo |
| **离散扩散** | 中高 | ⭐⭐⭐ | ✅ | ✅ 统一 | DD-VLA |

## 5. Action Chunking (动作分块)

不管哪种动作表示，都有一个共同趋势：**一次预测未来多步动作**。

```
单步预测：  观测 → 模型 → 1 步动作 → 执行 → 观测 → 模型 → 1 步动作 → ...
                                                ↑ 每步都要调用模型，延迟高

Action Chunking：观测 → 模型 → [未来 16 步动作] → 依次执行 → 16 步后再调用模型
                                                        ↑ 模型调用频率降低 16x
```

| 好处 | 说明 |
| :--- | :--- |
| **降低推理频率** | 模型不需要每步都推理，只需每 N 步推理一次 |
| **动作平滑** | 模型一次规划整段轨迹，不会出现逐步抖动 |
| **时间一致性** | 整段动作序列是一起生成的，保持时间上的连贯性 |

典型 Chunk 大小：
*   OpenVLA: 1（逐步）
*   Octo: 4
*   π0: 16-50
*   Diffusion Policy: 8-16

## 6. 发展趋势

```
2023:  均匀 Binning (RT-2)          ← 最简单，proof of concept
2024:  扩散策略 (π0, Octo)           ← 精度飞跃，但速度慢
2025:  FAST 频域编码 (π0-FAST)       ← 速度与精度的最佳平衡
2025:  离散扩散 (DD-VLA)             ← 统一框架的新尝试
```

> **一句话总结**：动作表示是 VLA 的"语言"——选对编码方式，决定了机器人是"粗糙地比划"还是"精准地操作"。从 Binning 到 FAST 到 Diffusion，趋势是**精度越来越高、速度也在追赶、与 LLM 框架越来越统一**。
