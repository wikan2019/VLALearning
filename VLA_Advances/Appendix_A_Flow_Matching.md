# 附录 A：Flow Matching 原理详解

> **前置知识**：[19. VLA 架构](./19_VLA_Architecture.md)（扩散范式章节）、[20. 动作表示](./20_Action_Tokenization.md)（为什么不用 Regression Head）

---

## 1. 从 Diffusion 到 Flow Matching：为什么需要一种新范式？

### (a) Diffusion 模型的成功与局限

**DDPM (Denoising Diffusion Probabilistic Models)** 是生成模型领域的里程碑，在图像、音频、动作生成中取得了巨大成功。它的核心思路是：

```
前向过程（加噪）:  真实数据 x₀ → x₁ → x₂ → ... → x_T ≈ 纯噪声 N(0, I)
反向过程（去噪）:  纯噪声 x_T → x_{T-1} → ... → x₁ → x₀ ≈ 生成数据
```

但 DDPM 有几个实际问题：

| 问题 | 说明 |
| :--- | :--- |
| **推理步数多** | 需要 50-1000 步去噪迭代，每步都要做一次神经网络前向推理 |
| **路径弯曲** | 从噪声到数据的路径是弯曲的随机游走（SDE），不是最短路径 |
| **训练目标间接** | 训练的是"噪声预测 ε_θ"，需要间接转换为数据方向 |
| **理论复杂** | 基于 SDE/随机微分方程，数学推导冗长 |

```
DDPM 的路径（弯曲的随机游走）:

噪声 x_T ─╮
           │╲
           │  ╲         弯弯曲曲的路径
           │    ╲       需要很多步才能走完
           │     ╲╮
           │      │╲
           │      │  ╲
           ╰──────╯   → 数据 x₀

路径曲率 ≈ 3.45（实测，非最优）
```

### (b) Flow Matching 的核心直觉

**Flow Matching 的核心思想极其简单：为什么不走直线？**

```
Flow Matching 的路径（接近直线）:

噪声 x₁ ─────────────────→ 数据 x₀

路径曲率 ≈ 1.02（接近理想直线）
步数: 5-20 步即可达到高质量生成（vs DDPM 的 50-1000 步）
```

这就是 Flow Matching 的全部直觉——学习一个**速度场 (velocity field)**，让数据沿着近似直线从噪声流向真实分布。

---

## 2. 数学基础：连续正则化流 (CNF)

### (a) 什么是"流 (Flow)"？

在数学中，**流**是一个随时间变化的映射，将点从一个位置"搬运"到另一个位置。

**定义**：流 \( \phi_t: \mathbb{R}^d \to \mathbb{R}^d \) 是一族参数为时间 \( t \in [0, 1] \) 的微分同胚（可逆、光滑的映射），满足：

```
常微分方程 (ODE):

  dx/dt = v_t(x)          ← v_t 是速度场 (velocity field)

初始条件:
  x(0) = x₀ ~ p₀         ← t=0 时从噪声分布出发
  x(1) ~ p₁               ← t=1 时到达数据分布

解:
  φ_t(x₀) = x₀ + ∫₀ᵗ v_s(φ_s(x₀)) ds
```

**直觉理解**：想象一大群粒子，每个粒子代表一个样本。速度场 \( v_t \) 告诉每个粒子在每个时刻该往哪个方向移动、移动多快。当所有粒子按照速度场流动，它们会从噪声分布"流向"数据分布。

```
t=0 (噪声分布)              t=0.5 (中间状态)              t=1 (数据分布)
                            
 · · ·  · · ·               ·  ··  ·                    ··
·   ·· · ·  ·         ·  ··     ··               ··    ···
  · ·  · ·· ·           ··   · ·  ·                ···  ··
· ·  ·  · · ·           · ··· ·                   ···
  ···  ·  · ·              · ··· ·                  ····

  均匀散布                 开始聚集                  形成数据结构
  (高斯噪声)                                        (如图像/动作)
```

### (b) 连续正则化流 (CNF)

CNF 是流的神经网络参数化版本：

```
CNF 定义:

  dx/dt = v_θ(x, t)       ← v_θ 是神经网络参数化的速度场

  其中 θ 是可学习参数

目标: 找到 θ 使得流 φ_t 将 p₀ (噪声) 映射到 p₁ (数据)
      即: (φ₁)_#p₀ = p_data
```

**概率密度的变化**遵循连续性方程（类似流体力学）：

```
连续性方程:

  ∂p_t/∂t + ∇·(p_t · v_t) = 0

含义: 概率守恒 —— 粒子不会凭空产生或消失
      只是在速度场的驱动下从一个区域"流"到另一个区域
```

---

## 3. Flow Matching 核心算法

### (a) 总体框架

Flow Matching 的训练目标是：**让神经网络 \( v_\theta(x, t) \) 拟合一个已知的目标速度场 \( u_t(x) \)**

```
Flow Matching 损失:

  L_FM(θ) = E_{t~U[0,1], x~p_t} [ ||v_θ(x, t) - u_t(x)||² ]

  其中:
    t ~ U[0, 1]        : 时间均匀采样
    x ~ p_t             : 从 t 时刻的分布中采样
    u_t(x)              : 目标速度场（已知的理想速度场）
    v_θ(x, t)           : 神经网络预测的速度场
```

**问题**：目标速度场 \( u_t(x) \) 和边际分布 \( p_t \) 是无法直接计算的——它们依赖于整个数据集的全局信息。

### (b) 条件 Flow Matching (CFM)：关键突破

**Conditional Flow Matching** 通过"条件化"解决了上述问题——不看全局，只看**以单个数据点为条件**的局部速度场。

```
条件 Flow Matching 损失:

  L_CFM(θ) = E_{t~U[0,1], x₁~p_data, x~p_t(·|x₁)} [ ||v_θ(x, t) - u_t(x|x₁)||² ]

  其中:
    x₁ ~ p_data          : 从训练集采样一个真实数据点
    p_t(x|x₁)            : 以 x₁ 为条件的概率路径
    u_t(x|x₁)            : 以 x₁ 为条件的速度场（可以解析计算！）
```

**关键定理（Lipman et al., 2023）**：

```
定理: L_CFM(θ) 与 L_FM(θ) 具有相同的梯度

  ∇_θ L_CFM(θ) = ∇_θ L_FM(θ)

证明直觉: 对所有条件 x₁ 取期望后，条件速度场恢复为边际速度场
          因此优化 L_CFM 等价于优化 L_FM
```

这意味着：**我们可以用简单的条件速度场来训练，但得到的模型能拟合全局速度场！**

### (c) 高斯概率路径

最常用的概率路径是**线性插值路径（Optimal Transport 路径）**：

```
线性插值路径:

  p_t(x|x₁) = N(x; μ_t(x₁), σ_t²I)

  其中:
    μ_t(x₁) = t · x₁              ← 均值从 0 线性移到 x₁
    σ_t = 1 - (1-σ_min) · t       ← 方差从 1 线性缩小到 σ_min ≈ 0

采样方式:
  x = μ_t(x₁) + σ_t · ε,   ε ~ N(0, I)
  x = t · x₁ + (1-(1-σ_min)·t) · ε

简化版 (σ_min → 0):
  x_t = t · x₁ + (1-t) · x₀
  其中 x₀ ~ N(0, I) (噪声), x₁ ~ p_data (数据)
```

**对应的条件速度场：**

```
u_t(x|x₁) = (x₁ - (1-σ_min)·x) / (1-(1-σ_min)·t)

简化版 (σ_min → 0):
  u_t(x|x₁) = (x₁ - x) / (1-t)

更简洁的表达:
  u_t(x_t|x₁) = x₁ - x₀ = x₁ - ε

  即: 速度场就是 "数据减去噪声" 的方向！
```

---

## 4. 完整训练与推理流程

### (a) 训练流程

```
╔══════════════════════════════════════════════════════════════════════╗
║                    Flow Matching 训练流程                            ║
╠══════════════════════════════════════════════════════════════════════╣
║                                                                      ║
║  循环每个 mini-batch:                                                ║
║                                                                      ║
║  ① 采样数据: x₁ ~ p_data     (从训练集取一个真实样本)                ║
║  ② 采样噪声: x₀ ~ N(0, I)    (标准高斯噪声)                        ║
║  ③ 采样时间: t ~ U[0, 1]     (均匀采样时间步)                       ║
║                                                                      ║
║  ④ 构造插值: x_t = (1-t)·x₀ + t·x₁                                ║
║                     ↑ 噪声和数据的线性混合                           ║
║                                                                      ║
║  ⑤ 计算目标速度: u = x₁ - x₀                                       ║
║                       ↑ 从噪声指向数据的方向                         ║
║                                                                      ║
║  ⑥ 网络预测:   v̂ = v_θ(x_t, t)                                     ║
║                                                                      ║
║  ⑦ 计算损失:   L = ||v̂ - u||²                                      ║
║                                                                      ║
║  ⑧ 反向传播更新 θ                                                   ║
║                                                                      ║
╚══════════════════════════════════════════════════════════════════════╝
```

**伪代码**：

```python
# Flow Matching 训练
for x1 in dataloader:           # x1: 真实数据 (如机器人动作)
    x0 = torch.randn_like(x1)   # 标准高斯噪声
    t = torch.rand(batch_size)   # 均匀采样 t ∈ [0, 1]

    # 线性插值
    xt = (1 - t) * x0 + t * x1   # 中间状态

    # 目标速度场 = 数据 - 噪声
    target_velocity = x1 - x0

    # 网络预测速度
    pred_velocity = model(xt, t)

    # MSE 损失
    loss = F.mse_loss(pred_velocity, target_velocity)
    loss.backward()
    optimizer.step()
```

### (b) 推理流程（采样/生成）

```
╔══════════════════════════════════════════════════════════════════════╗
║                    Flow Matching 推理流程                            ║
╠══════════════════════════════════════════════════════════════════════╣
║                                                                      ║
║  ① 从噪声出发: x₀ ~ N(0, I)                                        ║
║                                                                      ║
║  ② 用 ODE 积分器沿速度场推进 (t: 0 → 1):                            ║
║                                                                      ║
║     Euler 方法 (最简单):                                             ║
║       for k = 0, 1, ..., N-1:                                        ║
║         t_k = k / N                                                  ║
║         Δt = 1 / N                                                   ║
║         x_{k+1} = x_k + Δt · v_θ(x_k, t_k)                         ║
║                          ↑ 神经网络预测的速度                         ║
║                                                                      ║
║  ③ 输出: x_N ≈ x₁ ~ p_data                                         ║
║                                                                      ║
╚══════════════════════════════════════════════════════════════════════╝

具象化过程 (N=5 步):

t=0.0      t=0.2      t=0.4      t=0.6      t=0.8      t=1.0
 x₀ ──v₀──→ x₁ ──v₁──→ x₂ ──v₂──→ x₃ ──v₃──→ x₄ ──v₄──→ x₅
噪声                                                        数据
(随机)                                                   (高质量)
```

**伪代码**：

```python
# Flow Matching 推理（Euler 方法）
def sample(model, shape, num_steps=10):
    x = torch.randn(shape)         # 从噪声开始
    dt = 1.0 / num_steps

    for k in range(num_steps):
        t = k / num_steps
        v = model(x, t)            # 预测速度
        x = x + dt * v             # Euler 步进

    return x                        # 生成的样本
```

---

## 5. Flow Matching vs DDPM：核心差异

### (a) 数学框架对比

```
┌─────────────────────────────────────────────────────────────────┐
│                        DDPM (扩散模型)                          │
├─────────────────────────────────────────────────────────────────┤
│ 框架:  随机微分方程 (SDE)                                       │
│        dx = f(x,t)dt + g(t)dW                                   │
│                              ↑ 随机项 (布朗运动)                │
│                                                                  │
│ 前向:  q(x_t|x_0) = N(√ᾱ_t · x_0, (1-ᾱ_t)I)                  │
│        路径: 弯曲的、随机的                                     │
│                                                                  │
│ 训练:  预测噪声 ε_θ(x_t, t) ≈ ε                                │
│        L = E[||ε_θ(x_t, t) - ε||²]                             │
│                                                                  │
│ 推理:  x_{t-1} = μ_θ(x_t, t) + σ_t · z,  z ~ N(0,I)          │
│        需要 50-1000 步                                           │
└─────────────────────────────────────────────────────────────────┘

┌─────────────────────────────────────────────────────────────────┐
│                     Flow Matching (流匹配)                       │
├─────────────────────────────────────────────────────────────────┤
│ 框架:  常微分方程 (ODE)                                         │
│        dx = v_θ(x, t)dt                                         │
│                          ↑ 没有随机项！确定性轨迹               │
│                                                                  │
│ 插值:  x_t = (1-t)·x₀ + t·x₁                                  │
│        路径: 直线                                                │
│                                                                  │
│ 训练:  预测速度 v_θ(x_t, t) ≈ x₁ - x₀                          │
│        L = E[||v_θ(x_t, t) - (x₁ - x₀)||²]                    │
│                                                                  │
│ 推理:  x_{k+1} = x_k + Δt · v_θ(x_k, t_k)                     │
│        只需 5-20 步                                              │
└─────────────────────────────────────────────────────────────────┘
```

### (b) 路径可视化对比

```
DDPM 的路径:                        Flow Matching 的路径:
(随机弯曲的 SDE 轨迹)               (近似直线的 ODE 轨迹)

噪声 ·╮                            噪声 ·
       ╲                                   ╲
        ╲                                    ╲
         ╲╮                                    ╲
           │╲                                    ╲
           │  ╲                                    ╲
           │   ╲╮                                    ╲
           ╰────╲──→ 数据                              → 数据

轨迹曲率 ≈ 3.45                     轨迹曲率 ≈ 1.02
需要高阶 ODE solver                 一阶 Euler 即可
50-1000 步                          5-20 步
```

### (c) 量化对比

| 维度 | DDPM | Flow Matching |
| :--- | :--- | :--- |
| **底层方程** | SDE（随机微分方程） | ODE（常微分方程） |
| **训练目标** | 预测噪声 ε | 预测速度 v = x₁ - x₀ |
| **路径形状** | 弯曲随机轨迹 | 近似直线 |
| **路径曲率** | ~3.45 | ~1.02 |
| **推理步数** | 50-1000 (DDPM) / 20-50 (DDIM) | **5-20** |
| **ODE Solver** | 需要高阶 (RK45等) | 一阶 Euler 即可 |
| **训练稳定性** | 需要精心设计噪声调度 | 线性插值，无需调度 |
| **数学复杂度** | 高（SDE 理论） | **低（ODE + 线性插值）** |
| **生成质量** | 高 | **相当或更好** |

### (d) 全方位对比：Flow Matching 的优势与 DDPM 的优势

上面的对比聚焦于数学框架和路径差异。下面从**训练、推理、生成质量、适用场景**四个维度做全方位对比，回答一个关键问题：**Flow Matching 是否全面取代了 DDPM？**

#### Flow Matching 的优势（DDPM 做不到或做不好的）

```
优势 1: 推理效率 (最显著的优势)
──────────────────────────────────────────────────────

  DDPM:  50-1000 步 SDE/ODE 求解     → 生成一张图像需要数十秒
  DDIM:  20-50 步 (DDPM 的加速变体)   → 仍然较慢
  FM:    5-20 步 一阶 Euler            → 快 5-50 倍

  实测 (同等质量下):
    DDPM (1000步):   ~30 秒 / 张   (A100 GPU)
    DDIM (50步):     ~2 秒 / 张
    Flow Matching:   ~0.3 秒 / 张   ← 达到实时生成的门槛

  对 VLA 的意义:
    机器人需要 >10Hz 控制频率 → 每次推理 <100ms
    DDPM (50步):  每步 ~4ms × 50 = ~200ms  ❌ 超时
    FM (10步):    每步 ~4ms × 10 = ~40ms   ✅ 满足实时要求
```

```
优势 2: 训练简洁性
──────────────────────────────────────────────────────

  DDPM 需要设计:
    ① 噪声调度表 β_t (linear / cosine / sigmoid ...)
    ② 不同参数化 (ε-prediction / x₀-prediction / v-prediction)
    ③ 权重调度 (SNR weighting / Min-SNR / ...)
    → 每个选择都影响最终质量，需要大量调参

  Flow Matching:
    ① 线性插值: x_t = (1-t)·x₀ + t·x₁     ← 唯一选择
    ② 预测目标: v = x₁ - x₀                  ← 唯一选择
    ③ 损失: MSE                               ← 无需额外权重
    → 几乎没有超参数需要调整
```

```
优势 3: 数学框架简洁
──────────────────────────────────────────────────────

  DDPM:
    → SDE 理论、Fokker-Planck 方程、Score Function、Langevin 动力学
    → 数学门槛高，理解和实现都复杂

  Flow Matching:
    → ODE + 线性插值 + MSE
    → 本科微积分水平即可理解核心原理
    → 代码实现 <50 行
```

```
优势 4: 低资源硬件友好
──────────────────────────────────────────────────────

  实测 (CIFAR-10, 单块消费级 GPU):
    在 N=10 步 (函数评估次数) 的效率前沿:
    → Flow Matching: FID ≈ 12    (质量保持良好)
    → DDPM:          FID ≈ 85+   (质量严重崩溃!)

  原因: DDPM 的弯曲路径在低步数时无法用粗糙的离散化近似
        FM 的直线路径即使粗糙离散化也能保持合理的轨迹
```

#### DDPM 的优势（Flow Matching 做不到或做不好的）

```
优势 1: 随机性带来的误差纠正能力
──────────────────────────────────────────────────────

  DDPM (SDE 采样):
    x_{t-1} = μ_θ(x_t, t) + σ_t · z,    z ~ N(0, I)
                                ↑ 随机项!

  FM (ODE 采样):
    x_{k+1} = x_k + Δt · v_θ(x_k, t_k)
                                ↑ 没有随机项，完全确定性

  关键差异:
    当 v_θ 的预测有误差时 (神经网络不可能完美):

    ODE (FM): 误差会累积，因为没有随机性来"跳出"错误轨迹
              后续每一步都基于之前可能有误差的结果

    SDE (DDPM): 随机项 σ_t·z 可以起到"纠错"效果
                特别是在生成早期 (噪声大、t大) 时
                随机扰动可以帮助轨迹回到正确的流形上

  数学证明 (2025):
    当 score function 误差发生在生成早期时:
    → SDE 的大扩散系数能指数级压制误差
    → ODE 无此纠错能力
```

```
优势 2: 样本多样性
──────────────────────────────────────────────────────

  FM (ODE): 确定性采样
    → 相同的初始噪声 x₀ 必然生成完全相同的结果
    → 多样性完全依赖初始噪声的随机性

  DDPM (SDE): 随机采样
    → 相同的初始噪声 x₀ 也可能生成不同的结果
    → 每一步的随机扰动带来额外的多样性

  影响:
    在模型容量不足或训练不充分时:
    → FM 可能陷入"确定性的错误" (总是走同一条次优路径)
    → DDPM 的随机性可以帮助探索更多模态

  图像生成实例:
    提示词 "一只猫坐在沙发上"
    FM:  可能总是生成类似角度和姿态的猫 (多样性较低)
    DDPM: 每次采样的随机扰动带来不同的姿态和背景细节
```

```
优势 3: 小数据/低数据量场景
──────────────────────────────────────────────────────

  理论分析 (Diffusion Bridge vs FM, 2025):

    FM 的线性插值假设:
      x_t = (1-t)·x₀ + t·x₁
      → 隐含假设 Optimal Transport 是线性的
      → 当训练数据量不足时，这个假设可能不准确
      → 违反 Brenier 定理的条件

    Diffusion Bridge (DDPM 变体):
      → 漂移项 θ_t(x₁ - x_t) 持续将轨迹拉向目标
      → 提供连续的反馈机制
      → 在数据有限时更鲁棒

  实验结论:
    数据量充足 (>50K 样本): FM ≥ DDPM
    数据量有限 (<10K 样本): DDPM/Diffusion Bridge 可能更好
```

```
优势 4: 生态成熟度与工程实践
──────────────────────────────────────────────────────

  DDPM (2020 至今):
    → 5+ 年的社区积累
    → 丰富的开源工具 (diffusers, k-diffusion, ...)
    → 大量预训练模型 (Stable Diffusion 1.x/2.x/XL)
    → 成熟的 ControlNet、LoRA、DreamBooth 等下游工具
    → 社区对采样器 (DDIM, DPM++, UniPC) 的深入研究

  Flow Matching (2023 至今):
    → 相对年轻，生态仍在建设中
    → 预训练模型较少 (Flux, SD3 部分)
    → 下游工具正在迁移中
    → 社区经验积累不如 DDPM 丰富
```

#### 各自擅长的应用领域

```
┌─────────────────────────────────────────────────────────────────────┐
│                     应用领域适用性对比                                │
├─────────────────────────────────────────────────────────────────────┤
│                                                                      │
│  Flow Matching 更适合:                                               │
│  ─────────────────────                                               │
│  ✅ 机器人动作生成 (VLA)   → 实时性要求高，π0 是标杆                │
│  ✅ 实时图像生成           → Flux Schnell 亚秒级生成                 │
│  ✅ 视频生成               → Goku、MaskFlow 等新模型均采用 FM        │
│  ✅ 边缘设备部署           → 低步数 = 低算力需求                     │
│  ✅ 科学计算/分子生成      → 低维连续空间中 OT 路径最优              │
│  ✅ 追求训练简洁性的研究   → 超参数少，易于复现                      │
│                                                                      │
│  DDPM 更适合 / 至少持平:                                             │
│  ─────────────────────────                                           │
│  ✅ 高质量艺术风格图像     → SD XL 生态成熟，风格控制丰富            │
│  ✅ 小数据/专业领域微调    → 随机性提供鲁棒性                        │
│  ✅ 需要最大样本多样性     → SDE 随机采样提供额外多样性              │
│  ✅ 已有 DDPM 管线的项目   → 迁移成本高，没必要换                    │
│  ✅ 需要成熟工具链的部署   → ControlNet, LoRA 生态完善               │
│  ✅ 可控生成 (细粒度编辑)  → Classifier-Free Guidance 在 DDPM 中     │
│                               研究更成熟                              │
│                                                                      │
└─────────────────────────────────────────────────────────────────────┘
```

#### 产业采用现状 (截止 2026 年初)

| 模型/产品 | 架构 | 发布时间 | 说明 |
| :--- | :--- | :--- | :--- |
| Stable Diffusion 1.x/2.x/XL | DDPM | 2022-2023 | 里程碑产品，生态最完善 |
| DALL-E 3 | DDPM 变体 | 2023 | OpenAI 图像生成 |
| **Stable Diffusion 3** | **Flow Matching (MMDiT)** | 2024 | Stability AI 转向 FM |
| **Flux (Black Forest Labs)** | **Rectified Flow (FM)** | 2024 | 当前最强开源图像生成 |
| **Goku (ByteDance)** | **Rectified Flow** | 2025 | 视频生成 SOTA |
| Sora (OpenAI) | Diffusion Transformer | 2024 | 视频生成，具体细节未公开 |
| **π0 (Physical Intelligence)** | **Flow Matching** | 2024 | VLA 标杆 |
| Diffusion Policy | DDPM | 2023 | 机器人策略，仍广泛使用 |

**趋势清晰**：2024 年以后的新模型绝大多数选择 Flow Matching / Rectified Flow。DDPM 主要存在于已有模型的维护和迭代中。

#### 结论：FM 是否全面取代 DDPM？

```
┌─────────────────────────────────────────────────────────────────────┐
│                                                                      │
│  短回答: 没有全面取代，但正在成为新项目的默认选择。                  │
│                                                                      │
│  ┌─────────────────────────────────────────────────────────────────┐ │
│  │                                                                 │ │
│  │  FM 已经赢了的维度:                                             │ │
│  │    ✅ 推理效率 (完胜)                                           │ │
│  │    ✅ 训练简洁性 (完胜)                                         │ │
│  │    ✅ 数学优雅性 (完胜)                                         │ │
│  │    ✅ 新模型采用率 (2024+ 绝大多数新模型选 FM)                  │ │
│  │                                                                 │ │
│  │  DDPM 仍有优势的维度:                                           │ │
│  │    ⚠️ 随机采样的纠错与多样性 (SDE > ODE)                       │ │
│  │    ⚠️ 小数据场景的鲁棒性                                       │ │
│  │    ⚠️ 生态成熟度和工具链 (短期优势，正在被追赶)                │ │
│  │                                                                 │ │
│  │  本质区别:                                                      │ │
│  │    DDPM 和 FM 并非完全不同的东西——                               │ │
│  │    它们可以统一在 "连续时间生成模型" 的框架下。                  │ │
│  │    FM 可以看作 DDPM 的一个特例/简化，选择了更优的路径。          │ │
│  │    未来可能走向融合: 结合 FM 的直线路径 + 可选的随机扰动。       │ │
│  │                                                                 │ │
│  └─────────────────────────────────────────────────────────────────┘ │
│                                                                      │
│  类比:                                                               │
│    DDPM → FM 的关系，类似于 SGD → Adam 的关系:                       │
│    → Adam 更快、更简单、大多数情况更好                                │
│    → 但 SGD 在某些特定场景仍是最优选择                               │
│    → 新项目默认用 Adam，除非有特殊理由才用 SGD                       │
│    → 同理: 新项目默认用 FM，除非有特殊理由才用 DDPM                  │
│                                                                      │
└─────────────────────────────────────────────────────────────────────┘
```

---

## 6. Optimal Transport (OT) 路径

### (a) 为什么 OT 路径更好？

Flow Matching 的一个关键创新是使用 **Optimal Transport** 思想来设计概率路径——找到从噪声分布到数据分布的"最经济"搬运方式。

```
非 OT 路径（VP-SDE 风格）:          OT 路径（线性插值）:

x₀ ~ N(0,I)                         x₀ ~ N(0,I)
 │                                    │
 │  先膨胀方差                         │  直接线性插值
 │  再慢慢收缩                         │  走最短路径
 ╰───╮                                │
      ╲                                ╲
       ╲                                 → x₁ (数据)
        ╲
         → x₁ (数据)

传输代价: 高（走了弯路）              传输代价: 最低（最短路径）
```

**OT 的数学定义**：

```
Optimal Transport 问题:

  min_{γ ∈ Γ(p₀, p₁)} E_{(x₀,x₁)~γ} [ ||x₀ - x₁||² ]

  其中:
    p₀ = N(0, I)         : 噪声分布
    p₁ = p_data           : 数据分布
    Γ(p₀, p₁)            : 所有边际分布为 p₀ 和 p₁ 的联合分布
    γ                      : 传输方案（谁搬到哪里）

OT 路径的线性插值:
  x_t = (1-t) · x₀ + t · x₁    ← 在 OT 耦合 (x₀, x₁) 下的线性插值
```

### (b) OT 路径带来的好处

```
好处 1: 更直的路径 → 更少的步数
  ┌─────────────────────────────┐
  │ 弯路需要小步长才能跟随曲线   │
  │ 直路可以用大步长一步到位     │
  └─────────────────────────────┘

好处 2: 更简单的速度场 → 更容易学习
  ┌─────────────────────────────┐
  │ 弯曲速度场需要大网络来拟合   │
  │ 近线性速度场小网络也能学好   │
  └─────────────────────────────┘

好处 3: 更好的训练信号
  ┌─────────────────────────────┐
  │ 目标速度 u = x₁ - x₀       │
  │ 方差低，梯度更稳定          │
  └─────────────────────────────┘
```

---

## 7. Flow Matching 在 VLA 中的应用

### (a) π0：VLA 领域的标杆应用

**π0 (Physical Intelligence, 2024)** 是首个将 Flow Matching 大规模应用于机器人控制的 VLA 模型。

```
┌────────────────────────────────────────────────────────────────────┐
│                        π0 完整架构                                  │
├────────────────────────────────────────────────────────────────────┤
│                                                                     │
│  ┌───────────┐  ┌─────────────┐  ┌──────────────────┐              │
│  │ Multi-View │  │   Language   │  │  Proprioception  │              │
│  │   Images   │  │ Instruction  │  │  (关节角度等)    │              │
│  └─────┬─────┘  └──────┬──────┘  └────────┬─────────┘              │
│        │               │                   │                        │
│        ▼               ▼                   ▼                        │
│  ┌───────────┐  ┌─────────────┐  ┌──────────────────┐              │
│  │ SigLIP ViT│  │  Tokenizer  │  │     MLP 编码      │              │
│  │ (视觉编码) │  │ (文本Token) │  │  (本体感受Token)  │              │
│  └─────┬─────┘  └──────┬──────┘  └────────┬─────────┘              │
│        │               │                   │                        │
│        ▼               ▼                   ▼                        │
│  ╔═══════════════════════════════════════════════════╗               │
│  ║           PaliGemma VLM Backbone (3B)            ║               │
│  ║  ┌─────────────────────────────────────────────┐ ║               │
│  ║  │  标准 Transformer Attention Layers          │ ║               │
│  ║  │  (处理 视觉Token + 文本Token)               │ ║               │
│  ║  └─────────────────────┬───────────────────────┘ ║               │
│  ║                        │                          ║               │
│  ║                        ▼                          ║               │
│  ║  ┌─────────────────────────────────────────────┐ ║               │
│  ║  │  Action Expert Layers (~300M 额外参数)      │ ║               │
│  ║  │  (处理 噪声动作Token + 本体感受Token)       │ ║               │
│  ║  │  类似 MoE 的专家结构                        │ ║               │
│  ║  └─────────────────────┬───────────────────────┘ ║               │
│  ╚════════════════════════╪═══════════════════════════╝               │
│                           │                                          │
│                           ▼                                          │
│  ┌────────────────────────────────────────────────────┐              │
│  │              Flow Matching 解码                     │              │
│  │                                                     │              │
│  │  噪声 a₀ ~ N(0,I)                                  │              │
│  │    │                                                │              │
│  │    ├── t=0.0: v = v_θ(a₀, 0, h) → a₀.₁            │              │
│  │    ├── t=0.1: v = v_θ(a₀.₁, 0.1, h) → a₀.₂       │              │
│  │    ├── ...                                          │              │
│  │    └── t=0.9: v = v_θ(a₀.₉, 0.9, h) → a₁.₀       │              │
│  │                                                     │              │
│  │  输出: a₁.₀ = Action Chunk (未来 N 步动作)          │              │
│  │        [Δx, Δy, Δz, Δroll, Δpitch, Δyaw, grip]×N  │              │
│  └────────────────────────────────────────────────────┘              │
│                                                                     │
└────────────────────────────────────────────────────────────────────┘
```

### (b) π0 中 Flow Matching 的具体实现

**Step 1: 条件特征提取**

```
VLM 骨干网络处理视觉和语言输入，生成条件特征 h:

  h = VLM([image_tokens, text_tokens])

  h 编码了"当前看到什么"和"需要做什么"的完整语义信息
```

**Step 2: 训练时的 Flow Matching**

```
训练损失:

  L_FM = E_{a₁~p_data, a₀~N(0,I), t~U[0,1]} [ ||v_θ(a_t, t, h) - (a₁ - a₀)||² ]

  其中:
    a₁ = 真实动作 (人类演示中的动作 chunk)
    a₀ = 高斯噪声
    a_t = (1-t)·a₀ + t·a₁     ← 线性插值
    h = VLM 的条件特征
    v_θ = Action Expert 预测的速度场
```

**Step 3: 推理时的动作生成**

```
推理流程（N=10 步 Euler 积分）:

  a₀ ~ N(0, I)                    ← 从纯噪声开始
  
  for k = 0, 1, ..., 9:
    t = k / 10
    v = v_θ(a_k, t, h)            ← Action Expert 预测速度
    a_{k+1} = a_k + 0.1 · v       ← Euler 步进

  输出: a₁₀ ≈ [未来 50 步动作]    ← 高精度连续动作 chunk
```

### (c) π0 中 Action Expert 的设计

π0 的一个关键创新是 **Action Expert**——在 VLM 的 Transformer 中插入专门处理动作的额外参数：

```
标准 VLM 层:
  [视觉Token] [文本Token] → Self-Attention → FFN → 输出

π0 的混合层:
  [视觉Token] [文本Token]           → Self-Attention → FFN_shared → 输出₁
                                                          ↕
  [噪声动作Token] [本体Token] [t]   → Cross-Attention → FFN_action → 输出₂
                                         ↑                  ↑
                                    与 VLM 特征交互   Action Expert
                                                      (~300M 参数)

设计理由:
  ① 动作Token需要与视觉/语言Token交互（Cross-Attention）
  ② 但动作的表示空间与语言截然不同（需要专门的FFN）
  ③ 类似 MoE：共享注意力，但使用不同的FFN专家
```

### (d) 为什么 Flow Matching 特别适合 VLA？

| 特性 | 对 VLA 的意义 |
| :--- | :--- |
| **推理步数少 (5-20步)** | 机器人需要实时控制（>10Hz），DDPM 的 50-1000 步无法满足 |
| **路径直、学习简单** | 动作空间维度高（7维×50步=350维），简单的目标函数更容易优化 |
| **连续值输出** | 无离散化损失，灵巧操作（插钉、缝纫）需要亚毫米精度 |
| **多模态分布建模** | 通过随机初始噪声采样不同模态，避免 mode averaging |
| **Action Chunking 友好** | 一次去噪生成整段动作序列（50步），保证时间一致性 |
| **可与 VLM 联合训练** | ODE 框架与 Transformer 兼容，可端到端梯度传播 |

### (e) 实际性能

```
π0 性能 (7 种机器人, 68 个任务):

任务类型                    成功率
─────────────────────────────────
简单抓取 (单臂)             ~92%
多步操作 (叠衣服)           ~80%
精细操作 (装配)             ~75%
跨机器人泛化 (zero-shot)    ~60%

对比:
  OpenVLA (自回归 Binning):  精细操作 ~45%  ← 离散化精度不足
  Diffusion Policy (DDPM):   推理延迟 ~200ms ← 步数太多
  π0 (Flow Matching):        精细操作 ~75%, 推理延迟 ~50ms ← 两全其美
```

---

## 8. Flow Matching 的完整数学总结

### (a) 符号表

| 符号 | 含义 |
| :--- | :--- |
| \( x_0 \) | 噪声样本，\( x_0 \sim p_0 = \mathcal{N}(0, I) \) |
| \( x_1 \) | 数据样本，\( x_1 \sim p_1 = p_{\text{data}} \) |
| \( x_t \) | 时间 \( t \) 处的中间状态 |
| \( v_\theta(x, t) \) | 神经网络参数化的速度场 |
| \( u_t(x) \) | 目标边际速度场 |
| \( u_t(x \| x_1) \) | 以 \( x_1 \) 为条件的目标速度场 |
| \( p_t \) | 时间 \( t \) 处的边际概率密度 |
| \( \phi_t \) | 流映射（ODE 的解） |

### (b) 核心公式一览

```
┌─────────────────────────────────────────────────────────────┐
│  1. 线性插值路径                                             │
│     x_t = (1-t)·x₀ + t·x₁,    t ∈ [0, 1]                  │
│                                                              │
│  2. 条件速度场                                               │
│     u_t(x_t|x₁) = x₁ - x₀                                  │
│                                                              │
│  3. CFM 训练损失                                             │
│     L = E_{t,x₀,x₁} [ ||v_θ(x_t, t) - (x₁ - x₀)||² ]    │
│                                                              │
│  4. ODE 积分 (推理)                                          │
│     x_{k+1} = x_k + Δt · v_θ(x_k, t_k)                     │
│                                                              │
│  5. VLA 条件生成                                             │
│     L = E_{t,a₀,a₁} [ ||v_θ(a_t, t, h) - (a₁-a₀)||² ]    │
│     其中 h = VLM(image, text)                                │
│                                                              │
│  6. 连续性方程                                               │
│     ∂p_t/∂t + ∇·(p_t · v_t) = 0                             │
└─────────────────────────────────────────────────────────────┘
```

---

## 9. Flow Matching 的局限与前沿

### (a) 当前局限

| 局限 | 说明 |
| :--- | :--- |
| **仍需多步推理** | 虽然比 DDPM 少很多，但 5-20 步 ODE 仍比单次前向慢 |
| **确定性轨迹** | ODE 是确定性的，多样性完全依赖初始噪声的随机性 |
| **有限数据下表现下降** | 训练数据不足时，线性插值的假设可能不准确 |
| **对高频突变动作不友好** | 线性路径假设动作平滑，突变（碰撞、快速切换）可能建模不好 |

### (b) 前沿发展方向

```
2023:  Flow Matching 基础框架 (Lipman et al.)
2024:  π0 首次大规模应用于 VLA
2025:  几个活跃方向:

  ① 一步 Flow Matching (Consistency Flow Matching)
     → 将 ODE 蒸馏为单步生成，推理速度媲美 Regression Head
     → 保留多模态分布建模能力

  ② 离散 Flow Matching
     → 将 Flow Matching 扩展到离散空间（Token 生成）
     → 与 LLM 自回归框架更好地统一

  ③ 几何 Flow Matching
     → 在 SE(3) 等非欧几何空间上定义 Flow Matching
     → 适合机器人末端执行器的旋转表示

  ④ Rectified Flow (矫正流)
     → 通过多轮 "矫正" 让路径更直
     → 进一步减少推理步数（目标: 1-3 步）
```

---

## 10. 端到端流程图：从观测到动作

```
完整 VLA + Flow Matching 推理流程:

  ┌───────────────────────────────────────────────────────────────┐
  │ 环境观测                                                       │
  │  📷 腕部相机 + 📷 全局相机 + 🦾 关节角度 + 💬 "叠好毛巾"        │
  └──────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
  ┌───────────────────────────────────────────────────────────────┐
  │ 1. 视觉编码 (SigLIP ViT)                                      │
  │    RGB → Patch Embedding → ViT → 视觉 Token 序列              │
  └──────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
  ┌───────────────────────────────────────────────────────────────┐
  │ 2. VLM 推理 (PaliGemma 3B)                                    │
  │    [视觉Token] + [文本Token] → Transformer → 条件特征 h        │
  │    h 编码了："看到毛巾在桌上" + "需要叠好"                      │
  └──────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
  ┌───────────────────────────────────────────────────────────────┐
  │ 3. Flow Matching 生成 (Action Expert)                          │
  │                                                                │
  │    a₀ ~ N(0, I)     ← 随机噪声 (350 维: 7维×50步)            │
  │      │                                                         │
  │      │  ┌──────────────────────────────────┐                   │
  │      ├─→│ v = v_θ(a_t, t, h)               │ ×10 步           │
  │      │  │ a_{t+Δt} = a_t + Δt · v          │ Euler 积分       │
  │      │  └──────────────────────────────────┘                   │
  │      │                                                         │
  │      ▼                                                         │
  │    a₁ = [Δx₁,Δy₁,...,grip₁, Δx₂,...,grip₂, ..., grip₅₀]     │
  │         └──── 第1步 ────┘ └──── 第2步 ────┘      └─ 第50步 ┘  │
  └──────────────────────┬────────────────────────────────────────┘
                         │
                         ▼
  ┌───────────────────────────────────────────────────────────────┐
  │ 4. 执行                                                        │
  │    依次执行 50 步动作 → 50 步后重新观测 → 回到步骤 1           │
  └───────────────────────────────────────────────────────────────┘
```

---

## 参考文献

1. **Lipman, Y., Chen, R. T. Q., Ben-Hamu, H., et al.** (2023). *Flow Matching for Generative Modeling.* ICLR 2023. arXiv:2210.02747
2. **Black, K., Brown, N., et al.** (2024). *π0: A Vision-Language-Action Flow Model for General Robot Control.* arXiv:2410.24164
3. **Chi, C., Feng, S., Du, Y., et al.** (2023). *Diffusion Policy: Visuomotor Policy Learning via Action Score Gradients.* RSS 2023.
4. **Liu, X., Gong, C., Liu, Q.** (2023). *Flow Straight and Fast: Learning to Generate and Transfer Data with Rectified Flow.* ICLR 2023.
5. **Tong, A., Malkin, N., et al.** (2024). *Improving and Generalizing Flow-Based Generative Models with Minibatch Optimal Transport.* TMLR 2024.
6. **Chen, R. T. Q., Lipman, Y.** (2024). *Flow Matching Guide and Code.* arXiv:2412.06264

---

[⬅️ 返回 VLA 目录](./README.md) | [📖 20. 动作表示](./20_Action_Tokenization.md) | [📖 22. π0 系列](./22_Pi0_Generalist_Policy.md)
