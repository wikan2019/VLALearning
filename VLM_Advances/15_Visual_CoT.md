# 15. Reasoning: VQA -> Visual CoT (Chain-of-Thought)

VLM 正在从简单的“看图说话”向更深层次的“看图推理”演进。为了解决复杂的数学几何题、推理侦探题，单纯的 VQA (Visual Question Answering) 已经不够用了，必须引入 **Chain-of-Thought (CoT)**。

## 1. 传统 VQA 的局限
传统的 VQA 模型倾向于**走捷径 (Shortcut Learning)**。
*   **例子**：问“图片里的香蕉是什么颜色的？”
*   **模型**：直接猜“黄色”。根本没看图，因为训练集里 90% 的香蕉都是黄色的。
*   **后果**：遇到绿色香蕉或黑白图片时，模型会一本正经地胡说八道。

## 2. Visual Chain-of-Thought (多模态思维链)
受到 LLM CoT 的启发，VLM 开始被训练输出推理过程。
**格式**：`Thought: [分析步骤] -> Answer: [最终结论]`

### (a) 描述后推理 (Describe-then-Reason)
这是一种简单有效的策略：强制模型先描述图片细节，再回答问题。
*   *User*: “这辆车能停在这里吗？”
*   *Assistant*: “（观察）图片显示路边有红线。（知识）红线代表全路段禁停。（结论）不能。”

### (b) Visual CoT 数据集
数据集如 **ScienceQA** 包含了图片、问题、选项以及**详细的解释 (Lecture & Solution)**。
在这些数据上微调 VLM，能显著提升其科学推理能力（如 LLaVA-Sci, Sphinx）。

## 3. 进阶：V-STaR (Self-Taught Reasoner)
为了进一步提升推理能力，研究者引入了强化学习思想。
*   **机制**：
    1.  让 VLM 对一个问题生成多个推理路径。
    2.  如果最终答案正确，则将该条推理路径加入训练集。
    3.  如果错误，则生成修正后的路径。
*   **效果**：模型学会了自我反思和纠错，推理准确率在 MathVista 等榜单上大幅提升。

## 4. 多图推理 (Multi-Image Reasoning)
最新的模型（如 GPT-4V, Gemini 1.5）支持输入多张图片进行对比或时序分析。
*   **Interleaved Image-Text**：支持 `<Img1> 文字 <Img2> 文字...` 的输入格式。
*   这使得模型可以学习“找不同”、理解漫画剧情、分析视频关键帧。

## 5. 总结

| 特性 | VQA (传统) | Visual CoT (思维链) |
| :--- | :--- | :--- |
| **输出形式** | 直接给答案 (`Yes/No`, `Yellow`) | `观察 -> 分析 -> 结论` |
| **鲁棒性** | 差 (依赖偏见) | **强 (基于证据)** |
| **可解释性** | 无 (黑盒) | **有 (白盒推理)** |
| **典型应用** | 简单物体识别 | **几何题, 侦探推理, 医疗诊断** |
| **代表作** | Flamingo, early BLIP | **LLaVA-1.5, GPT-4o, Gemini 1.5** |
