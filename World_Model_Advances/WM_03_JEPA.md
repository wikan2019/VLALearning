# WM-03. JEPA：LeCun 的世界模型愿景

## 1. Yann LeCun 的核心主张

Meta 首席 AI 科学家 **Yann LeCun** 认为当前的 AI（包括 LLM）存在根本缺陷：

> **"自回归语言模型不是通向 AGI 的正确路径。我们需要世界模型——能够预测世界运作方式的内部模拟器。"**

LeCun 将他的愿景具体化为 **JEPA (Joint Embedding Predictive Architecture)** 架构——一种**非生成式**的世界模型。

## 2. JEPA vs 生成式世界模型

| 特性 | 生成式世界模型 (Sora, Genie) | JEPA |
| :--- | :--- | :--- |
| **预测什么** | 预测未来的**像素/视频帧** | 预测未来的**潜在表示** |
| **输出** | 可视化的视频 | 抽象的特征向量 |
| **信息处理** | 重建所有细节（包括无关的） | **丢弃不可预测的细节** |
| **效率** | 计算量巨大 | **高效（不需要生成像素）** |
| **类比** | 想象一部完整的电影 | 想象"接下来会发生什么"的抽象概念 |

**核心哲学差异**：
```
生成式: "预测每一个像素" → 信息过载，很多像素是不可预测的噪声
JEPA:   "预测本质特征"   → 丢弃噪声，只预测有意义的变化
```

> **类比**：预测"明天天气"有两种方式：
> *   生成式：渲染一幅逼真的明天的天空照片（需要画每一朵云）。
> *   JEPA：预测"明天晴，25°C，风力3级"（只预测关键特征）。

## 3. JEPA 架构详解

### 核心机制

```
┌──────────────────────────────────────────────────┐
│                 JEPA 架构                          │
│                                                    │
│  [输入 x]  → 编码器 → [嵌入 sₓ]                   │
│                                  ↘                 │
│                                   预测器 → [预测 ŝᵧ]  ──→ 比较
│                                  ↗                 │         ↕
│  [目标 y]  → 编码器 → [嵌入 sᵧ]  ────────────────→ [真实 sᵧ] │
│              (EMA 更新，不回传梯度)                   │
└──────────────────────────────────────────────────┘
```

**关键组件**：
1.  **上下文编码器 (Context Encoder)**：将输入 x 编码为嵌入向量 sₓ。
2.  **目标编码器 (Target Encoder)**：将目标 y 编码为嵌入向量 sᵧ。用 EMA（指数移动平均）更新，不参与梯度回传。
3.  **预测器 (Predictor)**：从 sₓ 预测 sᵧ。
4.  **损失函数**：`L = ||ŝᵧ - sᵧ||²`（在嵌入空间中比较，不在像素空间）。

**为什么不在像素空间比较？**
*   像素中有大量不可预测的信息（树叶的随机摇摆、水面的反光）。
*   在潜在空间中，这些不可预测的细节被自然过滤掉。
*   模型专注于预测**有意义的变化**（物体运动、状态转换）。

## 4. I-JEPA：图像世界模型（2023）

**I-JEPA (Image-JEPA)** 将 JEPA 应用于图像理解：

```
一张图片被分成多个 Patch：
  [P1] [P2] [P3] [P4]
  [P5] [P6] [P7] [P8]
  [P9] [P10][P11][P12]

遮蔽部分 Patch (如 P6, P7, P10, P11)：
  [P1] [P2] [P3] [P4]
  [P5] [██] [██] [P8]
  [P9] [██] [██] [P12]

任务：从可见 Patch 的嵌入，预测被遮蔽 Patch 的嵌入
（注意：是预测嵌入，不是重建像素！）
```

**vs MAE (Masked Autoencoder)**：
*   MAE 重建像素 → 容易被"无意义的纹理"主导。
*   I-JEPA 预测嵌入 → 聚焦于"语义内容"。

## 5. V-JEPA：视频世界模型（2024.02）

**V-JEPA** 将 JEPA 扩展到视频——这才是真正的"世界模型"：

```
视频帧序列：[F1 F2 F3 F4 F5 F6 F7 F8 F9 F10]

遮蔽连续的时空区域：
  [F1 F2 F3] [██ ██ ██ ██] [F8 F9 F10]

任务：从可见帧的嵌入，预测被遮蔽帧的嵌入
→ 模型必须理解"中间发生了什么" → 学会物理动态
```

### 关键成果

| 指标 | V-JEPA | 之前最好 |
| :--- | :--- | :--- |
| Kinetics-400 (动作识别) | **82.1%** | 78.0% |
| Something-Something-v2 (时间推理) | **71.2%** | 61.0% (+10!) |
| ImageNet (零样本图像分类) | 77.9% | — |

**惊人发现**：V-JEPA **只在视频上训练**（没有见过静态图片），但在 ImageNet 上也表现很好——说明视频中包含了图像的知识。

### 训练效率

V-JEPA 比生成式方法（如视频 MAE）的训练效率高 **1.5x - 6x**，因为它不需要重建像素。

## 6. V-JEPA 2：规模化世界模型（2025.06）

### (a) 核心升级

| 特性 | V-JEPA | V-JEPA 2 |
| :--- | :--- | :--- |
| **参数量** | ~300M | **1.2B** |
| **训练数据** | 视频数据集 | 更大规模视频 + 图像 |
| **核心能力** | 视觉表示学习 | **视觉理解 + 预测 + 机器人规划** |
| **零样本机器人** | ❌ | **✅ 零样本规划新环境** |

### (b) 零样本机器人规划

V-JEPA 2 最令人兴奋的能力是**零样本机器人规划**：

```
在新环境中（从未训练过）：
  1. V-JEPA 2 观察当前场景
  2. 给定目标（如"把杯子放到盘子上"）
  3. 在潜在空间中"想象"不同动作序列的结果
  4. 选择预测结果最接近目标的动作序列
  5. 执行

→ 无需任何机器人数据微调！
```

### (c) 物理推理基准

Meta 同时发布了新的物理推理基准，V-JEPA 2 在以下方面表现优异：
*   物体运动轨迹预测
*   碰撞结果预测
*   物理因果推理

## 7. JEPA 家族全景

```
JEPA (概念框架)
  ├── I-JEPA (图像)     → 语义级别的图像理解
  ├── V-JEPA (视频)     → 物理动态理解
  ├── V-JEPA 2 (大规模) → 零样本机器人规划
  └── VL-JEPA (多模态)  → 视觉+语言联合理解
```

## 8. JEPA vs Dreamer vs Sora

| 特性 | Dreamer V3 | JEPA (V-JEPA 2) | Sora |
| :--- | :--- | :--- | :--- |
| **预测空间** | 潜在空间 | 潜在空间 | 像素空间 |
| **需要解码器** | ✅ | ❌ | ✅ (生成视频) |
| **训练信号** | 奖励 + 重建 | 自监督 (无标签) | 文本条件生成 |
| **应用** | RL 智能体 | 表示学习 + 规划 | 视频生成 + 模拟 |
| **效率** | 中等 | **最高** | 最低 |
| **物理理解** | 隐式 | **显式（可验证）** | 初步 |
| **开源** | ✅ | ✅ | ❌ |

## 9. LeCun 的 AMI 蓝图

Yann LeCun 将 JEPA 定位在更大的 **AMI (Advanced Machine Intelligence)** 蓝图中：

```
┌─────────────────────────────────────────────┐
│              AMI 架构 (LeCun)                │
│                                             │
│  感知模块 → 世界模型 (JEPA) → 规划模块      │
│              ↑                   ↓          │
│          记忆模块            动作模块        │
│              ↑                   ↓          │
│          目标模块 ← 评估模块 ← 外部世界     │
└─────────────────────────────────────────────┘
```

**核心观点**：
1.  **世界模型是核心**，不是语言模型。
2.  世界模型应该**预测抽象表示**（JEPA），而不是像素（生成式）。
3.  自监督学习从视频中学习物理规律，无需人工标注。
4.  规划通过在世界模型中搜索最优动作序列来实现。

> **一句话总结**：JEPA 代表了世界模型的"高效路线"——不生成像素，只预测抽象表示，以 1.5-6x 的效率优势学习物理世界的运作规律。V-JEPA 2 (1.2B) 更进一步实现了零样本机器人规划，验证了 LeCun "世界模型是通向 AMI 的核心" 这一愿景的可行性。
