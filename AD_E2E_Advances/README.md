# 自动驾驶端到端技术进展学习文档索引

> 🚗 End-to-End Autonomous Driving 截止 2026 年 2 月的 11 项关键技术演进

[⬅️ 返回主目录](../README.md) | [📖 LLM 基础](../LLM_Advances/README.md) | [🎨 VLM 进展](../VLM_Advances/README.md) | [🤖 VLA 进展](../VLA_Advances/README.md)

---

## 📑 目录概览

自动驾驶正经历从**模块化流水线**到**端到端神经网络**的范式转变——这与机器人领域的 VLA 进展高度同步。

本文档汇总了端到端自动驾驶领域的核心技术演进，分为三大部分：

- **Part 6**: 感知基础 (文档 28-30)
- **Part 7**: 端到端架构与大模型 (文档 31-34)
- **Part 8**: 训练、安全与部署 (文档 35-38)

---

## Part 6: 自动驾驶感知基础

### 28. [从模块化到端到端：自动驾驶架构范式变革](./28_AD_Overview.md)
*   **演进点**：感知-预测-规划的模块化流水线 → 端到端神经网络
*   **核心价值**：理解自动驾驶为什么从规则驱动走向数据驱动，以及端到端方法如何解决模块间信息丢失的问题
*   **关键概念**：模块化 vs 端到端、开环 vs 闭环评估、信息瓶颈
*   **关联阅读**：→ [VLA/17. VLA 概述](../VLA_Advances/17_VLA_Overview.md)（同源的具身智能范式）

### 29. [BEV 感知：鸟瞰视角下的统一表示](./29_BEV_Perception.md)
*   **演进点**：2D 图像感知 → BEV 鸟瞰图统一表示 → 多传感器融合
*   **核心价值**：BEV 表示是端到端自动驾驶的基石——把多个相机/LiDAR 的输入统一到同一个三维空间中，为后续规划铺路
*   **代表模型**：BEVFormer, BEVDet, LSS, BEVFusion
*   **关联阅读**：→ [30. UniAD](./30_UniAD.md)（基于 BEV 的统一框架）

### 30. [UniAD：规划导向的统一自动驾驶框架](./30_UniAD.md)
*   **演进点**：独立的感知/预测/规划模块 → 以规划为目标的全任务统一模型
*   **核心价值**：CVPR 2023 最佳论文，首次证明将检测、跟踪、地图、预测、占据、规划全部统一在一个 Transformer 中可以获得全面提升
*   **代表模型**：UniAD, UniAD 2.0
*   **关联阅读**：→ [31. 占据网络](./31_Occupancy_Networks.md)、→ [32. 端到端规划](./32_E2E_Planning.md)

---

## Part 7: 端到端架构与大模型

### 31. [3D 占据网络：从检测框到体素化世界](./31_Occupancy_Networks.md)
*   **演进点**：3D 检测框 → 3D 占据体素 → 占据流预测
*   **核心价值**：占据网络用密集体素表示三维空间的占据状态，可以表示任意形状的障碍物（不仅仅是车辆和行人），是安全规划的关键输入
*   **代表方法**：OccNet, SurroundOcc, FlashOcc, GS-Occ3D
*   **关联阅读**：→ [29. BEV 感知](./29_BEV_Perception.md)（BEV 到占据的演进）

### 32. [端到端规划：从感知到控制的直通路径](./32_E2E_Planning.md)
*   **演进点**：规则规划器 → 学习规划器 → 生成式规划 → 统一生成
*   **核心价值**：端到端规划直接从传感器数据输出轨迹或控制指令，消除模块间的信息损失，是自动驾驶最核心的技术转变
*   **代表模型**：VAD, GenAD, DriveTransformer, UniUGP
*   **关联阅读**：→ [33. VLM 驾驶](./33_VLM_Driving.md)（大模型驱动的规划）

### 33. [VLM/VLA 驾驶：大模型遇上自动驾驶](./33_VLM_Driving.md)
*   **演进点**：专用驾驶模型 → VLM 作为驾驶大脑 → VLA 端到端驾驶
*   **核心价值**：将 VLM 的常识推理、场景理解和语言交互能力引入自动驾驶，实现可解释、可对话的驾驶决策
*   **代表模型**：EMMA (Waymo), DriveVLM, AutoVLA, LMDrive
*   **关联阅读**：→ [VLA/19. VLA 架构](../VLA_Advances/19_VLA_Architecture.md)（VLA 架构基础）

### 34. [驾驶世界模型：在脑中预演未来](./34_Driving_World_Models.md)
*   **演进点**：基于规则的仿真 → 神经网络仿真 → 生成式世界模型
*   **核心价值**：世界模型通过预测未来的驾驶视频来理解场景动态，可以用于规划决策、数据增强和安全验证
*   **代表模型**：GAIA-1/2, DriveDreamer, Drive-WM, GenAD
*   **关联阅读**：→ [VLA/24. 世界模型](../VLA_Advances/24_World_Models_Planning.md)（机器人世界模型）

---

## Part 8: 训练、安全与部署

### 35. [Tesla FSD：从规则到端到端神经网络](./35_Tesla_FSD.md)
*   **演进点**：C++ 规则引擎 → 端到端神经网络 (FSD v12/v13) → 推理 AI
*   **核心价值**：Tesla 是端到端自动驾驶最大规模的实际部署案例，70 亿+ 英里真实数据训练，理解其架构和演进路径对理解行业方向至关重要
*   **关键技术**：端到端 Transformer、数据引擎、影子模式、闭环训练
*   **关联阅读**：→ [36. 训练范式](./36_Training_Paradigms.md)（Tesla 的数据引擎）

### 36. [训练范式：模仿学习、强化学习与闭环训练](./36_Training_Paradigms.md)
*   **演进点**：行为克隆 → DAgger/闭环微调 → 世界模型 RL → 混合训练
*   **核心价值**：端到端模型的训练方式决定了其能力上限——开环模仿有"协变量漂移"瓶颈，闭环 RL 是突破上限的关键
*   **代表方法**：IL, DAgger, AD-R1, RoaD, RIFT, RAD
*   **关联阅读**：→ [VLA/Appendix A. Flow Matching](../VLA_Advances/Appendix_A_Flow_Matching.md)（生成式训练方法）

### 37. [安全验证与合规：端到端模型的可信赖之路](./37_Safety_Verification.md)
*   **演进点**：里程数验证 → 场景覆盖验证 → 形式化验证 → 可解释 AI
*   **核心价值**：端到端神经网络的"黑箱"特性是其最大的部署障碍——如何证明一个端到端模型足够安全？
*   **关键标准**：ISO/TS 5083:2025, EU Regulation 2022/1426, UNECE R157
*   **关联阅读**：→ [38. SOTA 对比](./38_AD_SOTA_Review.md)

### 38. [自动驾驶端到端 SOTA 全景对比 (截至 2026.02)](./38_AD_SOTA_Review.md)
*   **演进点**：当前最强端到端自动驾驶模型的横向对比与选型指南
*   **核心价值**：从架构、数据、性能、部署状态等维度全面对比 UniAD, VAD, EMMA, Tesla FSD 等模型
*   **代表系统**：UniAD, EMMA, Tesla FSD v13, Waymo Foundation Model, GenAD
*   **关联阅读**：→ [VLA/27. VLA SOTA](../VLA_Advances/27_VLA_SOTA_Review.md)（VLA 对比）

---

## 🔗 技术关联图

```
感知基础层 (Part 6):
28. 架构概述 → 29. BEV 感知 → 30. UniAD (统一框架)
                                     ↓
端到端架构层 (Part 7):
31. 占据网络 → 32. 端到端规划 → 33. VLM/VLA 驾驶
                                     ↓
                               34. 驾驶世界模型

训练与部署层 (Part 8):
35. Tesla FSD → 36. 训练范式 → 37. 安全验证
                                     ↓
                              38. SOTA 对比
```

---

## 🔄 与其他技术栈的关系

```
LLM (语言理解)
 ↓
VLM (视觉 + 语言理解)
 ↓
VLA (视觉 + 语言 + 动作执行)
 ↓
端到端自动驾驶 (VLA 在驾驶领域的具体应用) ← 你在这里
```

### 与 VLA 的关系

自动驾驶的端到端模型本质上就是一种 **VLA**——视觉输入是多路相机，语言输入是导航指令/交通规则，动作输出是轨迹/控制信号。但它有独特的挑战：

| 维度 | 通用 VLA (机器人) | 端到端自动驾驶 |
|------|-------------------|---------------|
| **安全等级** | 可接受偶尔失败 | 零容忍（关乎生命安全） |
| **速度** | 10-30 Hz | 10-36 Hz |
| **动作空间** | 6-14 DoF 关节 | 轨迹点 / 方向盘+油门+刹车 |
| **场景复杂度** | 桌面/室内 | 开放道路，无限复杂 |
| **传感器** | 1-3 个相机 | 6-8 相机 + LiDAR + 雷达 |
| **法规要求** | 极少 | 严格 (ISO, EU, UNECE) |
| **数据规模** | 百万轨迹 | 数十亿英里 |

---

## 📚 学习建议

### 🎯 新手路径
1. **前置知识**：先完成 [LLM](../LLM_Advances/README.md)、[VLM](../VLM_Advances/README.md)、[VLA](../VLA_Advances/README.md) 基础
2. **概述**：28 → 理解模块化 vs 端到端的范式差异
3. **核心技术**：29 → 30 → 32（BEV → UniAD → 端到端规划）
4. **产业实践**：35 → 38（Tesla FSD → SOTA 对比）

### 🚀 进阶路径
1. **感知深度**：29 → 31（BEV → 占据网络）
2. **大模型驾驶**：33 → 34（VLM 驾驶 → 世界模型）
3. **训练与安全**：36 → 37（闭环训练 → 安全验证）

---

## 📝 文档说明

- **Part 6（28-30）**：自动驾驶的感知基础和统一框架
- **Part 7（31-34）**：端到端架构、大模型驾驶和世界模型
- **Part 8（35-38）**：训练范式、安全验证和产业部署
- 所有文档包含：原理解析、数学公式、架构图、代表模型对比
- 大量跨文档引用，建议按技术栈顺序学习（LLM → VLM → VLA → AD E2E）

---

[⬅️ 返回主目录](../README.md) | [📖 LLM 基础](../LLM_Advances/README.md) | [🎨 VLM 进展](../VLM_Advances/README.md) | [🤖 VLA 进展](../VLA_Advances/README.md)
