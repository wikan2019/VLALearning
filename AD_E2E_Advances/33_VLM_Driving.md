# 33. VLM/VLA 驾驶：大模型遇上自动驾驶

[⬅️ 返回 AD 目录](./README.md)

> **核心问题**：传统端到端模型缺乏常识推理能力，VLM/VLA 如何弥补这一缺陷？

---

## 1. 为什么将大模型引入自动驾驶？

传统端到端 (E2E) 模型通过 **感知→预测→规划** 的数据驱动管线取得了显著进展，但存在根本局限：

| 局限性 | 说明 |
|---|---|
| **缺乏常识推理** | 模型只学到训练分布内的模式，无法处理 "看到救护车 → 让路" 等需要世界知识的场景 |
| **长尾场景脆弱** | 施工区域、异常天气、罕见交通参与者等场景数据稀少，模型泛化能力差 |
| **不可解释** | 输出一条轨迹，无法回答 "为什么这样开？" |
| **指令理解缺失** | 无法接受自然语言导航指令，如 "在前方药店右转" |

**VLM/VLA 带来的优势：**

- **世界知识注入**："学校区域 → 减速"、"前方有警察 → 规范驾驶" 等常识无需显式标注
- **自然语言接口**：可以用语言解释决策，也可以接受语言指令
- **Chain-of-Thought 推理**：面对复杂场景时可进行多步推理，而非直接回归轨迹
- **跨任务泛化**：预训练大模型天然具备零样本/少样本迁移能力

---

## 2. 两种架构范式

### (a) VLM-as-Planner — VLM 直接规划

VLM 同时承担感知与规划，端到端输出驾驶决策：

```
┌─────────────────────────────────────────────┐
│           VLM-as-Planner 架构                │
│                                             │
│  多帧图像 ──┐                                │
│             ├──→ [ VLM Backbone ] ──→ 文本轨迹 │
│  文本提示 ──┘    (Gemini/LLaVA)     (x,y) ×T │
│                                             │
│  特点：所有输入/输出均为 token 序列            │
└─────────────────────────────────────────────┘
```

**核心思路**：将轨迹坐标、检测框、道路拓扑全部表示为文本 token，统一在语言模型框架下训练。

**代表模型**：EMMA (Waymo)、LMDrive

---

### (b) Dual-System — 双系统架构

灵感来自认知科学的 System 1 / System 2 理论：

```
┌──────────────────────────────────────────────────────┐
│               Dual-System 架构                        │
│                                                      │
│  传感器输入 ──→ [场景复杂度评估] ──┬── 简单 ──→ System 1 │
│                                  │             (快速规划器) │
│                                  │             实时轨迹输出 │
│                                  │                        │
│                                  └── 复杂 ──→ System 2    │
│                                               (VLM 推理)  │
│                                               CoT → 决策  │
│                                                      │
│  两个系统的输出 ──→ [融合/切换] ──→ 最终轨迹              │
└──────────────────────────────────────────────────────┘
```

| 属性 | System 1 (快思考) | System 2 (慢思考) |
|---|---|---|
| **速度** | ~10ms，满足实时性 | ~500ms+，需要更多计算 |
| **能力** | 常规车道保持、跟车 | 复杂路口、异常场景推理 |
| **模型** | 轻量 E2E planner | VLM (7B–70B) |
| **触发条件** | 默认运行 | 场景复杂度超过阈值时激活 |

**代表模型**：DriveVLM、AutoVLA

---

## 3. 代表模型详解

### (a) EMMA — End-to-End Multimodal Model for Autonomous Driving

> Waymo, 2024 — 基于 Gemini 的纯文本驾驶模型

**核心设计**：

- **Backbone**：Gemini 多模态大模型，原生支持图像 + 文本输入
- **统一文本表示**：所有任务的输出均为文本 token
  - 轨迹：`"(1.2, 0.3), (2.5, 0.7), (3.8, 1.1), ..."`
  - 检测框：`"car at (x1, y1, x2, y2)"`
  - 道路拓扑：文本描述的有向图
- **多任务联合训练**：规划 + 3D 检测 + 道路图预测共享同一模型

```
输入：前视相机图像序列 + 文本 prompt
      "Given the driving scene, predict the future trajectory
       for the next 3 seconds at 2Hz..."

输出：文本格式的坐标序列
      "(0.5, 0.1), (1.1, 0.2), (1.8, 0.3), (2.6, 0.5), (3.5, 0.7), (4.3, 0.9)"
```

**实验结果**：

| 指标 | EMMA | UniAD | VAD |
|---|---|---|---|
| nuScenes L2 (3s) | **0.71** | 1.02 | 0.83 |
| Collision Rate | **0.13%** | 0.31% | 0.22% |

**局限性**：
- 仅用少量帧（无长时序建模）
- 不接入 LiDAR，纯视觉
- Gemini 推理代价高，实时部署困难
- 闭源模型，无法复现

---

### (b) DriveVLM — 链式推理驾驶

> 2024 — 将 VLM 的推理能力分层应用于驾驶

**三阶段推理链**：

```
┌─────────┐     ┌─────────┐     ┌──────────────┐     ┌──────────┐
│ 多视角   │ ──→ │ 场景描述  │ ──→ │ 场景分析      │ ──→ │ 层级规划  │
│ 图像输入 │     │ (D)      │     │ (A)          │     │ (P)      │
└─────────┘     └─────────┘     └──────────────┘     └──────────┘
                  "前方有施工     "施工区域占据右     决策：向左变道
                   区域标志，     车道，需要绕行，   路径：平滑左偏
                   右侧有锥桶"    左侧车道可通行"   速度：减速至30km/h
```

- **D (Description)**：VLM 生成场景的自然语言描述
- **A (Analysis)**：基于描述进行推理分析，识别关键因素
- **P (Planning)**：输出层级化的驾驶计划（决策 → 路径 → 速度）

**DriveVLM-Dual 变体**：VLM 输出高层决策，传统规划器负责低层轨迹生成，兼顾推理与实时性。

---

### (c) AutoVLA — 自适应双模 VLA

> 2025 — 自适应快/慢思考的视觉-语言-动作模型

**核心创新**：模型自主判断何时需要深度推理：

```
输入：驾驶场景图像 + ego 状态

┌─ 简单场景 (直行/跟车) ──→ 快思考模式
│   直接输出: trajectory tokens
│   延迟: ~50ms
│
└─ 复杂场景 (路口/异常) ──→ 慢思考模式
    输出: <think> 前方有行人正在过马路，
          需要减速等待... </think>
          trajectory tokens
    延迟: ~300ms
```

**GRPO (Group Relative Policy Optimization) 强化微调**：
- 奖励函数包含：轨迹准确度 + 推理必要性惩罚
- 鼓励模型在简单场景跳过 CoT，只在必要时推理
- 减少约 40% 的不必要推理，提升整体效率

---

### (d) LMDrive — 语言引导驾驶

> 2024 — 自然语言指令驱动的闭环驾驶

**设计要点**：
- 接受导航指令："在下个路口左转"、"跟随前方红色车辆"
- 在 CARLA 模拟器中进行闭环评测
- 多模态 token 融合：视觉特征 + 语言 embedding + LiDAR BEV

```
导航指令: "Turn left at the next intersection"
        + 多帧图像 + LiDAR
              ↓
    [ LLM-based Controller ]
              ↓
    控制信号: (throttle, steer, brake)
```

---

## 4. 关键技术：如何将驾驶知识注入 VLM

### (a) 驾驶专用微调数据

| 数据类型 | 内容 | 来源 |
|---|---|---|
| **场景描述 QA** | "图中有哪些交通参与者？" → 结构化回答 | nuScenes + GPT 标注 |
| **推理链标注** | 场景描述 → 风险分析 → 决策理由 → 动作 | 人工 + LLM 辅助 |
| **轨迹-语言对** | 将规划轨迹转化为坐标文本 | 自动生成 |
| **交规知识** | 交通法规、驾驶常识的文本语料 | 法规文档 |

### (b) 空间定位 (Spatial Grounding)

VLM 需要理解 **3D 空间**，而非仅仅描述图像内容：

- **坐标标准化**：将 ego 坐标系下的位置映射到 token（如量化为网格 ID）
- **视角对齐**：多相机图像拼接或分别编码后在 BEV 空间融合
- **深度感知**：引入深度估计辅助任务，或使用 3D position embedding

### (c) 轨迹的语言表示

```python
# 方案 1：直接坐标文本
trajectory = "(0.5, 0.1), (1.2, 0.3), (2.0, 0.5)"

# 方案 2：量化 token（类似 VQ-VAE）
trajectory = "<loc_23> <loc_45> <loc_67>"  # 预定义码本

# 方案 3：自然语言描述
trajectory = "直行 2 秒后缓慢向左变道，减速至 30km/h"
```

---

## 5. VLM 驾驶 vs 传统端到端：优劣对比

| 维度 | 传统 E2E (UniAD/VAD) | VLM 驾驶 (EMMA/DriveVLM) |
|---|---|---|
| **可解释性** | 低，黑盒轨迹输出 | **高**，可生成推理链 |
| **常识推理** | 无，纯数据驱动 | **有**，继承预训练知识 |
| **长尾处理** | 差，依赖数据覆盖 | **较好**，可推理泛化 |
| **实时性** | **好**，~20ms 推理 | 差，~500ms+ |
| **安全验证** | **较成熟**，可形式化分析 | 困难，LLM 行为难以保证 |
| **数据效率** | 需要大量标注驾驶数据 | **较好**，预训练迁移 |
| **部署成本** | **低**，轻量模型 | 高，需要大算力 |
| **多模态融合** | **灵活**，支持 LiDAR/Radar | 受限，多数仅支持图像+文本 |
| **指令交互** | 不支持 | **支持**，自然语言接口 |

**趋势判断**：两种范式并非替代关系，而是走向融合——**Dual-System 架构**正在成为主流方向，用传统 E2E 保证实时性和安全底线，用 VLM 处理需要推理的复杂场景。

---

## 6. 开放挑战

### (a) 实时推理瓶颈

当前 VLM（7B+ 参数）推理延迟远高于自动驾驶 ~100ms 的实时要求：

- **模型蒸馏**：将大模型的推理能力蒸馏到小模型
- **投机解码 (Speculative Decoding)**：小模型草拟 + 大模型验证
- **硬件加速**：车载 AI 芯片对 Transformer 的专项优化
- **Dual-System**：仅在必要时调用 VLM，降低平均延迟

### (b) 幻觉风险 (Hallucination)

VLM 可能"编造"不存在的障碍物或忽略真实危险：

- 在安全关键系统中，幻觉 = 致命错误
- 需要独立的感知校验模块作为安全网
- 置信度校准与 uncertainty estimation 至关重要

### (c) 推理正确性验证

即使 VLM 输出了合理的推理链，如何确保推理逻辑真正驱动了决策？

- CoT 可能是 "事后合理化" 而非真实推理过程
- 需要因果干预实验验证推理与动作的因果关系
- 形式化验证方法尚不成熟

### (d) 仿真到真实的迁移 (Sim-to-Real)

- 多数 VLM 驾驶模型仅在 nuScenes 开环评测或 CARLA 仿真中验证
- 真实世界闭环部署的鲁棒性仍未充分验证
- 传感器噪声、通信延迟等工程问题对 VLM 系统的影响尚不清楚

---

## 小结

| 要点 | 内容 |
|---|---|
| **核心价值** | VLM 为自动驾驶注入常识推理与可解释性 |
| **两大范式** | VLM-as-Planner（统一建模） vs Dual-System（快慢结合） |
| **代表工作** | EMMA、DriveVLM、AutoVLA、LMDrive |
| **关键挑战** | 实时性、幻觉、推理验证、Sim-to-Real |
| **发展方向** | Dual-System + 按需推理 + 轻量化部署 |

> **下一步**：随着端侧大模型（如 Gemini Nano、Phi-3）的成熟，VLM 驾驶有望从 "研究演示" 走向 "量产部署"。

---

[⬅️ 返回 AD 目录](./README.md)
